# LLM-Paper-Daily

## Awesome LLM Research

Welcome to the **Awesome LLM Research** repository! This project curates a list of high-quality resources related to LLM Research, including research papers, tools, libraries, and more.

## Daily Updates

### 2024-10-09

### 1. [Title:
          Revisiting the Superficial Alignment Hypothesis](https://arxiv.org/pdf/2410.03717)
- **Authors**: Mohit Raghavendra, Vaskar Nath, Sean Hendryx
- **Link**: https://arxiv.org/pdf/2410.03717
- **Abstract**: The Superficial Alignment Hypothesis posits that almost all of a language model's abilities and knowledge are learned during pre-training, while post-training is about giving a model the right style and format. We re-examine these claims by empirically studying the scaling behavior of post-training with increasing finetuning examples and evaluating them using objective task-specific standardized benchmarks. Through experiments with the Llama-3, Mistral, and Llama-2 model families of multiple sizes, we observe that, similar to the pre-training scaling laws, post-training task performance scales as a power law against the number of finetuning examples. This power law relationship holds across a broad array of capabilities, including mathematical reasoning, coding, instruction following, and multihop-reasoning. In addition, for tasks like math and multihop reasoning, we observe that a handful of examples merely align the model stylistically but do not saturate performance on the benchmarks. Model performance is instead correlated with its reasoning ability and it improves significantly with more examples, illustrating the need for holistic evaluation programs leveraging objective benchmarks in addition to measurement of alignment to human preferences. We also observe that language models are not necessarily limited to using knowledge learned during pre-training. With appropriate post-training, a model's ability to integrate new knowledge greatly improves on downstream tasks like multihop question-answering. Taken together, these results shed new light on the Superficial Alignment Hypothesis, suggesting that it is, at best, an over-simplification.
- **Keywords**: This paper is directly related to Large Language Models (LLMs) research. It focuses on the Superficial Alignment Hypothesis, which pertains to the learning and alignment processes of language models, particularly during pre-training and post-training phases. The study involves empirical analysis of scaling behavior with increasing fine-tuning examples, using models like Llama-3, Mistral, and Llama-2. The paper also discusses evaluation methods using objective benchmarks and the integration of new knowledge in downstream tasks, which are key aspects of LLM research. Additionally, the paper touches on the need for holistic evaluation programs and the implications of the findings for the broader field of LLM research.
- **Category**: LLM Research

### 2. [Title:
          Performance Evaluation of Tokenizers in Large Language Models for the Assamese Language](https://arxiv.org/pdf/2410.03718)
- **Authors**: Sagar Tamang, Dibya Jyoti Bora
- **Link**: https://arxiv.org/pdf/2410.03718
- **Abstract**: Training of a tokenizer plays an important role in the performance of deep learning models. This research aims to understand the performance of tokenizers in five state-of-the-art (SOTA) large language models (LLMs) in the Assamese language of India. The research is important to understand the multi-lingual support for a low-resourced language such as Assamese. Our research reveals that the tokenizer of SUTRA from Two AI performs the best with an average Normalized Sequence Length (NSL) value of 0.45, closely followed by the tokenizer of GPT-4o from Open AI with an average NSL value of 0.54, followed by Gemma 2, Meta Llama 3.1, and Mistral Large Instruct 2407 with an average NSL value of 0.82, 1.4, and 1.48 respectively.
- **Keywords**: This paper is related to Large Language Models (LLMs) research as it focuses on the performance evaluation of tokenizers in five state-of-the-art (SOTA) LLMs specifically for the Assamese language. The research addresses the performance of these models, which is a key aspect of LLMs research, particularly in the context of multi-lingual support for low-resourced languages. The evaluation method used, Normalized Sequence Length (NSL), is also relevant to the performance assessment of LLMs.
- **Category**: LLM Research

### 3. [Title:
          Thematic Analysis with Open-Source Generative AI and Machine Learning: A New Method for Inductive Qualitative Codebook Development](https://arxiv.org/pdf/2410.03721)
- **Authors**: Andrew Katz, Gabriella Coloyan Fleming, Joyce Main
- **Link**: https://arxiv.org/pdf/2410.03721
- **Abstract**: This paper aims to answer one central question: to what extent can open-source generative text models be used in a workflow to approximate thematic analysis in social science research? To answer this question, we present the Generative AI-enabled Theme Organization and Structuring (GATOS) workflow, which uses open-source machine learning techniques, natural language processing tools, and generative text models to facilitate thematic analysis. To establish validity of the method, we present three case studies applying the GATOS workflow, leveraging these models and techniques to inductively create codebooks similar to traditional procedures using thematic analysis. Specifically, we investigate the extent to which a workflow comprising open-source models and tools can inductively produce codebooks that approach the known space of themes and sub-themes. To address the challenge of gleaning insights from these texts, we combine open-source generative text models, retrieval-augmented generation, and prompt engineering to identify codes and themes in large volumes of text, i.e., generate a qualitative codebook. The process mimics an inductive coding process that researchers might use in traditional thematic analysis by reading text one unit of analysis at a time, considering existing codes already in the codebook, and then deciding whether or not to generate a new code based on whether the extant codebook provides adequate thematic coverage. We demonstrate this workflow using three synthetic datasets from hypothetical organizational research settings: a study of teammate feedback in teamwork settings, a study of organizational cultures of ethical behavior, and a study of employee perspectives about returning to their offices after the pandemic. We show that the GATOS workflow is able to identify themes in the text that were used to generate the original synthetic datasets.
- **Keywords**: This paper is relevant to Large Language Models (LLMs) research as it discusses the use of open-source generative text models and machine learning techniques, specifically in the context of thematic analysis and codebook development. The paper explores the application of these models in a workflow (GATOS) that aims to approximate traditional thematic analysis methods, demonstrating their utility in generating qualitative codebooks. This involves the use of generative text models, retrieval-augmented generation, and prompt engineering, which are all pertinent to LLMs research, particularly in the areas of model application and evaluation.
- **Category**: LLM Research



---

*Last updated on 2024-10-09*